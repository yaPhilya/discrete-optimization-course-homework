{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Задание по курсу «Дискретная оптимизация», МФТИ, весна 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Задача 2-2. Эвристика Кернигана—Лина\n",
    "\n",
    "В этой задаче Вам предлагается добавить к локальному поиска в задаче о сбалансированном разбиении графа эвристику Кернигана—Лина, когда мы, «застряв» в локальном минимуме, тем не менее пытаемся сделать несколько шагов из него, даже если они приводят к временному ухудшению. Надежда здесь на то, что после ухудшения может наступить заметное улучшение результата: нам удастся выпрыгнуть из локального оптимума. Мы рассматриваем безвесовый вариант задачи о разбиении с параметром балансировки $\\alpha=\\frac{1}{2}$:\n",
    "\n",
    "**Даны:**\n",
    "* $G=(V,E)$ — граф без весов на рёбрах\n",
    "\n",
    "**Найти:**\n",
    "* Разбиение $V=V'\\sqcup V''$, такое, что $V'=\\lfloor |V|/2 \\rfloor$ и число рёбер между $V'$ и $V''$ минимально возможное.\n",
    "\n",
    "Сделайте следующее:\n",
    "* Скачайте файл [`partition-instances.zip`](https://github.com/dainiak/discrete-optimization-course/raw/master/partition-instances.zip) и разархивируйте из него файлы со входами задачи.\n",
    "* Для каждого из графов найдите локальным поиском с эвристикой Кернигана—Лина локально минимальное (по количеству рёбер между частями) разбиение вершин графа на две части, мощности которых отличаются не более чем на единицу. \n",
    "* Реализуйте функцию `variable_depth_local_search`; она должна принимать на вход граф в формате, предоставляемом функцией `read_instance`, и возвращать найденное разбиение как множество вершин, лежащих в одной любой из двух компонент разбиения. Ваш локальный поиск должен начинаться с того разбиение, которое уже находится в переменной `starting_point`.\n",
    "* Подберите для каждого из четырёх входных графов глубину поиска так, чтобы он работал не более 60 секунд на Вашем компьютере, и сохраните информацию о подобранных параметрах и любые свои интересные наблюдения в отдельную ячейку настоящего ipynb-файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_instance(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        n_vertices = int(file.readline().strip().split()[0])\n",
    "        vertices, edges = set(range(1, n_vertices + 1)), set()\n",
    "        for u in range(1, n_vertices + 1):\n",
    "            for v in map(int, file.readline().strip().split()):\n",
    "                edges.add((u,v))\n",
    "        return (vertices, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_edges(edges, cut):\n",
    "    ans = 0\n",
    "    for edge in edges:\n",
    "        if not(set(edge) <= cut[0] or set(edge) <= cut[1]):\n",
    "            ans += 1\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_nearest(edges, cut, k):\n",
    "    ans = (0, 0)\n",
    "    best_dist = count_edges(edges, cut)\n",
    "    tmp = np.zeros(len(cut[0]) + len(cut[1]) + 1)\n",
    "    tmp[list(cut[1])] = 1\n",
    "    for first in cut[0]:\n",
    "        for second in cut[1]:\n",
    "            sum_first = tmp[list(edges[first])].sum()\n",
    "            sum_second = tmp[list(edges[second])].sum()\n",
    "            dist = best_dist + (len(edges[first]) - sum_first) - sum_first + sum_second - (len(edges[second]) - sum_second)\n",
    "            if dist < best_dist:\n",
    "                best_dist, ans = dist, (first, second)\n",
    "    cut[0].add(ans[1])\n",
    "    cut[0].remove(ans[0])\n",
    "    cut[1].add(ans[0])\n",
    "    cut[1].remove(ans[1])\n",
    "    return [cut[0], cut[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def variable_depth_local_search(graph):\n",
    "    vertices = graph[0]\n",
    "    edges = graph[1]\n",
    "    new_edges = [[] for i in range(len(graph[0]) + 1)]\n",
    "    for edge in edges:\n",
    "        new_edges[edge[0]].append(edge[1])\n",
    "        new_edges[edge[1]].append(edge[0])\n",
    "    cut = [set(range(1, len(graph[0]) // 2 + 1)), vertices.difference(set(range(1, len(graph[0]) // 2 + 1)))]\n",
    "    \n",
    "    np_cut = np.zeros(len(vertices) + 1)\n",
    "    np_cut[list(cut[1])] = 1\n",
    "    \n",
    "    sum_vert = np.zeros(len(vertices) + 1)\n",
    "    for v in range(1, len(vertices) + 1):\n",
    "        sum_vert[v] = np_cut[new_edges[v]].sum()\n",
    "    cnt_edge = np.zeros(len(vertices) + 1)\n",
    "    for v in vertices:\n",
    "        cnt_edge[v] = len(new_edges[v])\n",
    "    current = count_edges(edges, cut)\n",
    "    MAX_DEPTH = 1\n",
    "    while True:\n",
    "        res = False\n",
    "        cur_dist = current\n",
    "        exception = [-1, -2]\n",
    "        for i in range(MAX_DEPTH):\n",
    "            ans = [0, 0]\n",
    "            best_dist = 99999999999999\n",
    "            for first in cut[0]:\n",
    "                for second in cut[1]:\n",
    "                    if({first, second} <= set(exception)):\n",
    "                        continue\n",
    "                    sum_first = sum_vert[first]\n",
    "                    sum_second = sum_vert[second]\n",
    "                    dist = cur_dist + (cnt_edge[first] - sum_first) - sum_first + sum_second - (cnt_edge[second] - sum_second)\n",
    "                    if dist < best_dist:\n",
    "                        best_dist, ans = dist, [first, second]\n",
    "            cut[0].add(ans[1])\n",
    "            cut[0].remove(ans[0])\n",
    "            cut[1].add(ans[0])\n",
    "            cut[1].remove(ans[1])\n",
    "            np_cut[ans[1]] = 0\n",
    "            np_cut[ans[0]] = 1\n",
    "            sum_vert[new_edges[ans[1]]] -= 1\n",
    "            sum_vert[new_edges[ans[0]]] += 1\n",
    "            exception = [ans[0], ans[1]]\n",
    "            if best_dist < current:\n",
    "                current = best_dist\n",
    "                res = True\n",
    "                break\n",
    "            else:\n",
    "                cur_dist = best_dist\n",
    "        if res == False:\n",
    "            break\n",
    "    return cut[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_quality(graph, partition_part):\n",
    "    if not (partition_part <= graph[0]) or abs(len(partition_part) - len(graph[0]) / 2) > 0.6:\n",
    "        return -1\n",
    "    other_part = set(graph[0]) - partition_part\n",
    "    return sum(1 for edge in graph[1] if set(edge) <= partition_part or set(edge) <= other_part )\n",
    "\n",
    "def run_all():\n",
    "    filenames = ['add20.graph', 'cti.graph', 't60k.graph', 'm14b.graph']\n",
    "    for filename in filenames:\n",
    "        instance = read_instance(filename)\n",
    "        print('Solving instance {}…'.format(filename), end='')\n",
    "        time_start = time.monotonic()\n",
    "        quality = get_quality(instance, variable_depth_local_search(instance))\n",
    "        time_elapsed = time.monotonic()-time_start\n",
    "        print(' done in {:.2} seconds with quality {}'.format(time_elapsed, quality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving instance add20.graph… done in 1.5e+02 seconds with quality 11876\n",
      "Solving instance cti.graph… done in 3e+02 seconds with quality 94072\n",
      "Solving instance t60k.graph… done in 3.2e+03 seconds with quality 178248\n",
      "Solving instance m14b.graph…"
     ]
    }
   ],
   "source": [
    "run_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "Как видим даже для параметра 1 (просто локальный поиск) алгоритм работает очень долго. Как еще ускорить я не знаю, на мой взгляд я предподсчитал все что было возможно, а избавиться от 3 вложенных циклов невозможно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
